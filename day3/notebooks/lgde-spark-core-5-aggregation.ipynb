{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5교시 집계 연산\n",
    "\n",
    "### 목차\n",
    "* [1. 집계 함수](#1.-집계-함수)\n",
    "* [2. 그룹 함수](#2.-그룹-함수)\n",
    "* [참고자료](#참고자료)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from IPython.display import display, display_pretty, clear_output, JSON\n",
    "\n",
    "spark = (\n",
    "    SparkSession\n",
    "    .builder\n",
    "    .config(\"spark.sql.session.timeZone\", \"Asia/Seoul\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "# 노트북에서 테이블 형태로 데이터 프레임 출력을 위한 설정을 합니다\n",
    "spark.conf.set(\"spark.sql.repl.eagerEval.enabled\", True) # display enabled\n",
    "spark.conf.set(\"spark.sql.repl.eagerEval.truncate\", 100) # display output columns size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" 구매 이력 데이터 \"\"\"\n",
    "df = (\n",
    "    spark.read.format(\"csv\")\n",
    "    .option(\"header\", \"true\")\n",
    "    .option(\"inferSchema\", \"true\")\n",
    "    .load(\"data/retail-data/all\")\n",
    "    .coalesce(5)\n",
    ")\n",
    "df.cache()\n",
    "df.createOrReplaceTempView(\"dfTable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----------------------------------+--------+--------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|Description                        |Quantity|InvoiceDate   |UnitPrice|CustomerID|Country       |\n",
      "+---------+---------+-----------------------------------+--------+--------------+---------+----------+--------------+\n",
      "|536365   |85123A   |WHITE HANGING HEART T-LIGHT HOLDER |6       |12/1/2010 8:26|2.55     |17850     |United Kingdom|\n",
      "|536365   |71053    |WHITE METAL LANTERN                |6       |12/1/2010 8:26|3.39     |17850     |United Kingdom|\n",
      "|536365   |84406B   |CREAM CUPID HEARTS COAT HANGER     |8       |12/1/2010 8:26|2.75     |17850     |United Kingdom|\n",
      "|536365   |84029G   |KNITTED UNION FLAG HOT WATER BOTTLE|6       |12/1/2010 8:26|3.39     |17850     |United Kingdom|\n",
      "|536365   |84029E   |RED WOOLLY HOTTIE WHITE HEART.     |6       |12/1/2010 8:26|3.39     |17850     |United Kingdom|\n",
      "+---------+---------+-----------------------------------+--------+--------------+---------+----------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "541909"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.show(5, truncate=False)\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 집계 함수\n",
    "### 1.1 로우 수 (count, countDistinct, approx_count_distinct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- InvoiceNo: string (nullable = true)\n",
      " |-- StockCode: string (nullable = true)\n",
      " |-- Description: string (nullable = true)\n",
      " |-- Quantity: integer (nullable = true)\n",
      " |-- InvoiceDate: string (nullable = true)\n",
      " |-- UnitPrice: double (nullable = true)\n",
      " |-- CustomerID: integer (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|  541909|\n",
      "+--------+\n",
      "\n",
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|    1454|\n",
      "+--------+\n",
      "\n",
      "+------------------+\n",
      "|count(Description)|\n",
      "+------------------+\n",
      "|            540455|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "\n",
    "df.selectExpr(\"count(*)\").show()\n",
    "df.where(\"Description is null\").selectExpr(\"count(1)\").show() # 1,454\n",
    "df.selectExpr(\"count(Description)\").show() # 540,455 + 1,454 = 541,909"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+\n",
      "|count(DISTINCT StockCode)|\n",
      "+-------------------------+\n",
      "|                     4070|\n",
      "+-------------------------+\n",
      "\n",
      "+-------------------------+\n",
      "|count(DISTINCT StockCode)|\n",
      "+-------------------------+\n",
      "|                     4070|\n",
      "+-------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "# 명시적으로 컬럼을 지정한 경우 해당 컬럼이 널 인 경우 해당 로우는 제외됩니다\n",
    "df.select(countDistinct(\"StockCode\")).show()\n",
    "df.selectExpr(\"count(distinct StockCode)\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------+\n",
      "|approx_count_distinct(StockCode)|\n",
      "+--------------------------------+\n",
      "|                            3364|\n",
      "+--------------------------------+\n",
      "\n",
      "+--------------------------------+\n",
      "|approx_count_distinct(StockCode)|\n",
      "+--------------------------------+\n",
      "|                            4079|\n",
      "+--------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "# 근사치로 구하지만 연산 속도가 빠름\n",
    "df.select(approx_count_distinct(\"StockCode\", 0.1)).show() # 0.1은 최대 추정 오류율\n",
    "df.select(approx_count_distinct(\"StockCode\", 0.01)).show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 수치 집계 함수 (first, last, min, max, sum, sumDistinct, avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+----------------------+\n",
      "|first(StockCode, false)|last(StockCode, false)|\n",
      "+-----------------------+----------------------+\n",
      "|                 85123A|                 22138|\n",
      "+-----------------------+----------------------+\n",
      "\n",
      "+-------------+-------------+\n",
      "|min(Quantity)|max(Quantity)|\n",
      "+-------------+-------------+\n",
      "|       -80995|        80995|\n",
      "+-------------+-------------+\n",
      "\n",
      "+--------------------+-----------------+\n",
      "|    min(Description)| max(Description)|\n",
      "+--------------------+-----------------+\n",
      "| 4 PURPLE FLOCK D...|wrongly sold sets|\n",
      "+--------------------+-----------------+\n",
      "\n",
      "+-------------+\n",
      "|sum(Quantity)|\n",
      "+-------------+\n",
      "|      5176450|\n",
      "+-------------+\n",
      "\n",
      "+----------------------+\n",
      "|sum(DISTINCT Quantity)|\n",
      "+----------------------+\n",
      "|                 29310|\n",
      "+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "df.select(first(\"StockCode\"), last(\"StockCode\")).show(1) # null도 감안하려면 True\n",
    "\n",
    "df.select(min(\"Quantity\"), max(\"Quantity\")).show(1)\n",
    "df.select(min(\"Description\"), max(\"Description\")).show(1) # 문자열\n",
    "\n",
    "df.select(sum(\"Quantity\")).show(1)\n",
    "df.select(sumDistinct(\"Quantity\")).show(1) # 고유값을 합산"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 통계 집계 함수 (avg, mean, variance, stddev) \n",
    "* 표본표준분산 및 편차: variance, stddev\n",
    "* 모표준분산 및 편차 : var_pop, stddev_pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------+----------------+-----------------+\n",
      "|(total_purchases / total_transcations)|   avg_purchases|mean_transcations|\n",
      "+--------------------------------------+----------------+-----------------+\n",
      "|                      9.55224954743324|9.55224954743324| 9.55224954743324|\n",
      "+--------------------------------------+----------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "\n",
    "df.select(\n",
    "    count(\"Quantity\").alias(\"total_transcations\"),\n",
    "    sum(\"Quantity\").alias(\"total_purchases\"),\n",
    "    avg(\"Quantity\").alias(\"avg_purchases\"),\n",
    "    expr(\"mean(Quantity)\").alias(\"mean_transcations\"),    \n",
    ").selectExpr(\n",
    "    \"total_purchases / total_transcations\",\n",
    "    \"avg_purchases\",\n",
    "    \"mean_transcations\").show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+---------------------+------------------+---------------------+------------------+--------------------+\n",
      "|var_samp(Quantity)|stddev_samp(Quantity)|var_samp(Quantity)|stddev_samp(Quantity)| var_pop(Quantity)|stddev_pop(Quantity)|\n",
      "+------------------+---------------------+------------------+---------------------+------------------+--------------------+\n",
      "|47559.391409298696|   218.08115785023404|47559.391409298696|   218.08115785023404|47559.303646609005|  218.08095663447784|\n",
      "+------------------+---------------------+------------------+---------------------+------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\n",
    "    variance(\"Quantity\")\n",
    "    , stddev(\"Quantity\")\n",
    "    , var_samp(\"Quantity\")\n",
    "    , stddev_samp(\"Quantity\")\n",
    "    , var_pop(\"Quantity\")\n",
    "    , stddev_pop(\"Quantity\")\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 그룹 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 표현식을 이용한 그룹화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- InvoiceNo: string (nullable = true)\n",
      " |-- StockCode: string (nullable = true)\n",
      " |-- Description: string (nullable = true)\n",
      " |-- Quantity: integer (nullable = true)\n",
      " |-- InvoiceDate: string (nullable = true)\n",
      " |-- UnitPrice: double (nullable = true)\n",
      " |-- CustomerID: integer (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      "\n",
      "+---------+----------+---------------+\n",
      "|InvoiceNo|CustomerId|CountOfQuantity|\n",
      "+---------+----------+---------------+\n",
      "|   536846|     14573|             76|\n",
      "|   537026|     12395|             12|\n",
      "|   537883|     14437|              5|\n",
      "|   538068|     17978|             12|\n",
      "|   538279|     14952|              7|\n",
      "+---------+----------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import count\n",
    "df.printSchema()\n",
    "df.groupBy(\"InvoiceNo\", \"CustomerId\").agg(expr(\"count(Quantity) as CountOfQuantity\")).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 맵을 이용한 그룹화\n",
    "> 파이선의 딕셔너리 데이터 타입을 활용하여 집계함수의 표현이 가능 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------------------+------------------+\n",
      "|InvoiceNo|stddev_pop(UnitPrice)|     avg(Quantity)|\n",
      "+---------+---------------------+------------------+\n",
      "|   536596|    6.618375094302897|               1.5|\n",
      "|   536938|   2.4313249096586267|33.142857142857146|\n",
      "|   537252|                  0.0|              31.0|\n",
      "|   537691|    2.761232695735729|              8.15|\n",
      "|   538041|                  0.0|              30.0|\n",
      "+---------+---------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"InvoiceNo\").agg( { \"Quantity\" : \"avg\", \"UnitPrice\" : \"stddev_pop\" } ).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=blue>1. [중급]</font> 구매 이력 CSV \"data/retail-data/all\" 파일을 읽고\n",
    "#### 1. 스키마를 출력하세요\n",
    "#### 2. 데이터 10건을 출력하세요\n",
    "#### 3. 상품코드(StockCode)의 유일한 값의 갯수를 출력하세요\n",
    "#### 4. 상품단가(UnitPrice)의 최소, 최대 값을 출력하세요\n",
    "#### 5. 송장번호(StockCode)별로 송장별총매출금액(TotalInvoicePrice)를 계산하고 내림차순으로 정렬하세요\n",
    "#### 6. 송장별총매출금액(TotalInvoicePrice)이 최고금액이 송장을 필터하여 검증해 보세요\n",
    "##### 예를 들어 `select sum(unit-price * quantity) from table where invoiceno = '123456'` 와 같은 쿼리로 검증이 가능합니다\n",
    "\n",
    "<details><summary>[실습7] 출력 결과 확인 </summary>\n",
    "\n",
    "> 아래와 유사하게 방식으로 작성 되었다면 정답입니다\n",
    "\n",
    "```python\n",
    "df1 = (\n",
    "    spark.read.format(\"csv\")\n",
    "    .option(\"header\", \"true\")\n",
    "    .option(\"inferSchema\", \"true\")\n",
    "    .load(\"data/retail-data/all\")\n",
    ")\n",
    "df1.printSchema()\n",
    "df1.show()\n",
    "answer = df1.withColumn(\"TotalPrice\", expr(\"UnitPrice * Quantity\")).groupBy(\"InvoiceNo\").agg(sum(\"TotalPrice\").alias(\"TotalInvoicePrice\"))\n",
    "answer.printSchema()\n",
    "display(answer.orderBy(desc(\"TotalInvoicePrice\")).limit(10))\n",
    "\n",
    "df1.where(\"InvoiceNo = '581483'\").select(sum(expr(\"UnitPrice * Quantity\"))).show()\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- InvoiceNo: string (nullable = true)\n",
      " |-- StockCode: string (nullable = true)\n",
      " |-- Description: string (nullable = true)\n",
      " |-- Quantity: integer (nullable = true)\n",
      " |-- InvoiceDate: string (nullable = true)\n",
      " |-- UnitPrice: double (nullable = true)\n",
      " |-- CustomerID: integer (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      "\n",
      "+---------+---------+--------------------+--------+--------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|         Description|Quantity|   InvoiceDate|UnitPrice|CustomerID|       Country|\n",
      "+---------+---------+--------------------+--------+--------------+---------+----------+--------------+\n",
      "|   536365|   85123A|WHITE HANGING HEA...|       6|12/1/2010 8:26|     2.55|     17850|United Kingdom|\n",
      "|   536365|    71053| WHITE METAL LANTERN|       6|12/1/2010 8:26|     3.39|     17850|United Kingdom|\n",
      "|   536365|   84406B|CREAM CUPID HEART...|       8|12/1/2010 8:26|     2.75|     17850|United Kingdom|\n",
      "|   536365|   84029G|KNITTED UNION FLA...|       6|12/1/2010 8:26|     3.39|     17850|United Kingdom|\n",
      "|   536365|   84029E|RED WOOLLY HOTTIE...|       6|12/1/2010 8:26|     3.39|     17850|United Kingdom|\n",
      "|   536365|    22752|SET 7 BABUSHKA NE...|       2|12/1/2010 8:26|     7.65|     17850|United Kingdom|\n",
      "|   536365|    21730|GLASS STAR FROSTE...|       6|12/1/2010 8:26|     4.25|     17850|United Kingdom|\n",
      "|   536366|    22633|HAND WARMER UNION...|       6|12/1/2010 8:28|     1.85|     17850|United Kingdom|\n",
      "|   536366|    22632|HAND WARMER RED P...|       6|12/1/2010 8:28|     1.85|     17850|United Kingdom|\n",
      "|   536367|    84879|ASSORTED COLOUR B...|      32|12/1/2010 8:34|     1.69|     13047|United Kingdom|\n",
      "|   536367|    22745|POPPY'S PLAYHOUSE...|       6|12/1/2010 8:34|      2.1|     13047|United Kingdom|\n",
      "|   536367|    22748|POPPY'S PLAYHOUSE...|       6|12/1/2010 8:34|      2.1|     13047|United Kingdom|\n",
      "|   536367|    22749|FELTCRAFT PRINCES...|       8|12/1/2010 8:34|     3.75|     13047|United Kingdom|\n",
      "|   536367|    22310|IVORY KNITTED MUG...|       6|12/1/2010 8:34|     1.65|     13047|United Kingdom|\n",
      "|   536367|    84969|BOX OF 6 ASSORTED...|       6|12/1/2010 8:34|     4.25|     13047|United Kingdom|\n",
      "|   536367|    22623|BOX OF VINTAGE JI...|       3|12/1/2010 8:34|     4.95|     13047|United Kingdom|\n",
      "|   536367|    22622|BOX OF VINTAGE AL...|       2|12/1/2010 8:34|     9.95|     13047|United Kingdom|\n",
      "|   536367|    21754|HOME BUILDING BLO...|       3|12/1/2010 8:34|     5.95|     13047|United Kingdom|\n",
      "|   536367|    21755|LOVE BUILDING BLO...|       3|12/1/2010 8:34|     5.95|     13047|United Kingdom|\n",
      "|   536367|    21777|RECIPE BOX WITH M...|       4|12/1/2010 8:34|     7.95|     13047|United Kingdom|\n",
      "+---------+---------+--------------------+--------+--------------+---------+----------+--------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "root\n",
      " |-- InvoiceNo: string (nullable = true)\n",
      " |-- AveragePerInvoice: double (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>InvoiceNo</th><th>AveragePerInvoice</th></tr>\n",
       "<tr><td>581483</td><td>168469.6</td></tr>\n",
       "<tr><td>541431</td><td>77183.6</td></tr>\n",
       "<tr><td>574941</td><td>52940.93999999999</td></tr>\n",
       "<tr><td>576365</td><td>50653.909999999996</td></tr>\n",
       "<tr><td>556444</td><td>38970.0</td></tr>\n",
       "<tr><td>567423</td><td>31698.159999999996</td></tr>\n",
       "<tr><td>556917</td><td>22775.930000000008</td></tr>\n",
       "<tr><td>572209</td><td>22206.0</td></tr>\n",
       "<tr><td>567381</td><td>22104.8</td></tr>\n",
       "<tr><td>563614</td><td>21880.439999999995</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+---------+------------------+\n",
       "|InvoiceNo| AveragePerInvoice|\n",
       "+---------+------------------+\n",
       "|   581483|          168469.6|\n",
       "|   541431|           77183.6|\n",
       "|   574941| 52940.93999999999|\n",
       "|   576365|50653.909999999996|\n",
       "|   556444|           38970.0|\n",
       "|   567423|31698.159999999996|\n",
       "|   556917|22775.930000000008|\n",
       "|   572209|           22206.0|\n",
       "|   567381|           22104.8|\n",
       "|   563614|21880.439999999995|\n",
       "+---------+------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------+\n",
      "|sum((UnitPrice * Quantity))|\n",
      "+---------------------------+\n",
      "|                   168469.6|\n",
      "+---------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 여기에 실습 코드를 작성하고 실행하세요 (Shift+Enter)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=green>2. [기본]</font> 매출 테이블 \"data/tbl_purchase.csv\" CSV 파일을 읽고\n",
    "#### 1. 스키마를 출력하세요\n",
    "#### 2. 데이터 10건을 출력하세요\n",
    "#### 3. 제품(p_name)별 금액(p_amount) 의 전체 합인 총 매출금액(sum_amount)을 구하세요\n",
    "\n",
    "<details><summary>[실습2] 출력 결과 확인 </summary>\n",
    "\n",
    "> 아래와 유사하게 방식으로 작성 되었다면 정답입니다\n",
    "\n",
    "```python\n",
    "df2 = (\n",
    "    spark.read.format(\"csv\")\n",
    "    .option(\"header\", \"true\")\n",
    "    .option(\"inferSchema\", \"true\")\n",
    "    .load(\"data/tbl_purchase.csv\")\n",
    ")\n",
    "df2.printSchema()\n",
    "df2.show()\n",
    "answer = df2.groupBy(\"p_name\").agg(sum(\"p_amount\").alias(\"sum_amount\"))\n",
    "answer.printSchema()\n",
    "display(answer)\n",
    "\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>p_name</th><th>sum_amount</th></tr>\n",
       "<tr><td>LG Gram</td><td>5300000</td></tr>\n",
       "<tr><td>LG Computer</td><td>4500000</td></tr>\n",
       "<tr><td>LG Cyon</td><td>1400000</td></tr>\n",
       "<tr><td>LG TV</td><td>3500000</td></tr>\n",
       "<tr><td>GoldStar TV</td><td>100000</td></tr>\n",
       "<tr><td>LG DIOS</td><td>2000000</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-----------+----------+\n",
       "|     p_name|sum_amount|\n",
       "+-----------+----------+\n",
       "|    LG Gram|   5300000|\n",
       "|LG Computer|   4500000|\n",
       "|    LG Cyon|   1400000|\n",
       "|      LG TV|   3500000|\n",
       "|GoldStar TV|    100000|\n",
       "|    LG DIOS|   2000000|\n",
       "+-----------+----------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 여기에 실습 코드를 작성하고 실행하세요 (Shift+Enter)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=green>3. [기본]</font> 매출 테이블 \"data/tbl_purchase.csv\" CSV 파일을 읽고\n",
    "#### 1. 스키마를 출력하세요\n",
    "#### 2. 데이터 10건을 출력하세요\n",
    "#### 3. 구매 금액의 합이 가장 높은 고객(p_uid)을 구하세요\n",
    "\n",
    "<details><summary>[실습3] 출력 결과 확인 </summary>\n",
    "\n",
    "> 아래와 유사하게 방식으로 작성 되었다면 정답입니다\n",
    "\n",
    "```python\n",
    "df3 = (\n",
    "    spark.read.format(\"csv\")\n",
    "    .option(\"header\", \"true\")\n",
    "    .option(\"inferSchema\", \"true\")\n",
    "    .load(\"data/tbl_purchase.csv\")\n",
    ")\n",
    "df3.printSchema()\n",
    "df3.show()\n",
    "answer = df2.groupBy(\"p_uid\").agg(sum(\"p_amount\").alias(\"sum_amount_per_user\"))\n",
    "answer.printSchema()\n",
    "display(answer)\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>p_uid</th><th>sum_amount_per_user</th></tr>\n",
       "<tr><td>5</td><td>6000000</td></tr>\n",
       "<tr><td>4</td><td>4500000</td></tr>\n",
       "<tr><td>1</td><td>3800000</td></tr>\n",
       "<tr><td>2</td><td>1400000</td></tr>\n",
       "<tr><td>3</td><td>1000000</td></tr>\n",
       "<tr><td>0</td><td>100000</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-----+-------------------+\n",
       "|p_uid|sum_amount_per_user|\n",
       "+-----+-------------------+\n",
       "|    5|            6000000|\n",
       "|    4|            4500000|\n",
       "|    1|            3800000|\n",
       "|    2|            1400000|\n",
       "|    3|            1000000|\n",
       "|    0|             100000|\n",
       "+-----+-------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 여기에 실습 코드를 작성하고 실행하세요 (Shift+Enter)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=red>4. [고급]</font> 샌프란시스코 긴급출동 데이터 CSV 파일인 \"data/learning-spark/sf-fire-calls.csv\"를 읽고\n",
    "#### 1. 스키마를 출력하세요\n",
    "#### 2. 데이터를 3건 출력하세요\n",
    "#### 3. 호출의 종류(CallType)가 어떤 것들이 있는지 출력하세요 (중복제거)\n",
    "#### 3. 샌프란시스코에서 발생의 가장 빈도수가 높은 종류(CallType)를 구하고 빈도수를 구하세요\n",
    "#### 4. 샌프란시스코에서 발생하는 최고 빈도수 3건은 무엇인가요? \n",
    "\n",
    "<details><summary>[실습3] 출력 결과 확인 </summary>\n",
    "\n",
    "> 아래와 유사하게 방식으로 작성 되었다면 정답입니다\n",
    "\n",
    "```python\n",
    "df3 = (\n",
    "    spark\n",
    "    .read\n",
    "    .option(\"header\", \"true\")\n",
    "    .option(\"inferSchema\", \"true\")\n",
    "    .csv(\"data/learning-spark/sf-fire-calls.csv\")\n",
    ")\n",
    "df3.printSchema()\n",
    "df3.show(3)\n",
    "df3.createOrReplaceTempView(\"fire_calls\")\n",
    "spark.sql(\"select distinct(CallType) from fire_calls\").show(truncate=False)\n",
    "\n",
    "answer = spark.sql(\"select CallType, count(CallType) as CallTypeCount from fire_calls group by CallType order by CallTypeCount desc\")\n",
    "display(answer.limit(3))\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- CallNumber: integer (nullable = true)\n",
      " |-- UnitID: string (nullable = true)\n",
      " |-- IncidentNumber: integer (nullable = true)\n",
      " |-- CallType: string (nullable = true)\n",
      " |-- CallDate: string (nullable = true)\n",
      " |-- WatchDate: string (nullable = true)\n",
      " |-- CallFinalDisposition: string (nullable = true)\n",
      " |-- AvailableDtTm: string (nullable = true)\n",
      " |-- Address: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- Zipcode: integer (nullable = true)\n",
      " |-- Battalion: string (nullable = true)\n",
      " |-- StationArea: string (nullable = true)\n",
      " |-- Box: string (nullable = true)\n",
      " |-- OriginalPriority: string (nullable = true)\n",
      " |-- Priority: string (nullable = true)\n",
      " |-- FinalPriority: integer (nullable = true)\n",
      " |-- ALSUnit: boolean (nullable = true)\n",
      " |-- CallTypeGroup: string (nullable = true)\n",
      " |-- NumAlarms: integer (nullable = true)\n",
      " |-- UnitType: string (nullable = true)\n",
      " |-- UnitSequenceInCallDispatch: integer (nullable = true)\n",
      " |-- FirePreventionDistrict: string (nullable = true)\n",
      " |-- SupervisorDistrict: string (nullable = true)\n",
      " |-- Neighborhood: string (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- RowID: string (nullable = true)\n",
      " |-- Delay: double (nullable = true)\n",
      "\n",
      "+----------+------+--------------+----------------+----------+----------+--------------------+--------------------+--------------------+----+-------+---------+-----------+----+----------------+--------+-------------+-------+-------------+---------+--------+--------------------------+----------------------+------------------+--------------------+--------------------+-------------+---------+\n",
      "|CallNumber|UnitID|IncidentNumber|        CallType|  CallDate| WatchDate|CallFinalDisposition|       AvailableDtTm|             Address|City|Zipcode|Battalion|StationArea| Box|OriginalPriority|Priority|FinalPriority|ALSUnit|CallTypeGroup|NumAlarms|UnitType|UnitSequenceInCallDispatch|FirePreventionDistrict|SupervisorDistrict|        Neighborhood|            Location|        RowID|    Delay|\n",
      "+----------+------+--------------+----------------+----------+----------+--------------------+--------------------+--------------------+----+-------+---------+-----------+----+----------------+--------+-------------+-------+-------------+---------+--------+--------------------------+----------------------+------------------+--------------------+--------------------+-------------+---------+\n",
      "|  20110016|   T13|       2003235|  Structure Fire|01/11/2002|01/10/2002|               Other|01/11/2002 01:51:...|2000 Block of CAL...|  SF|  94109|      B04|         38|3362|               3|       3|            3|  false|         null|        1|   TRUCK|                         2|                     4|                 5|     Pacific Heights|(37.7895840679362...|020110016-T13|     2.95|\n",
      "|  20110022|   M17|       2003241|Medical Incident|01/11/2002|01/10/2002|               Other|01/11/2002 03:01:...|0 Block of SILVER...|  SF|  94124|      B10|         42|6495|               3|       3|            3|   true|         null|        1|   MEDIC|                         1|                    10|                10|Bayview Hunters P...|(37.7337623673897...|020110022-M17|      4.7|\n",
      "|  20110023|   M41|       2003242|Medical Incident|01/11/2002|01/10/2002|               Other|01/11/2002 02:39:...|MARKET ST/MCALLIS...|  SF|  94102|      B03|         01|1455|               3|       3|            3|   true|         null|        1|   MEDIC|                         2|                     3|                 6|          Tenderloin|(37.7811772186856...|020110023-M41|2.4333334|\n",
      "+----------+------+--------------+----------------+----------+----------+--------------------+--------------------+--------------------+----+-------+---------+-----------+----+----------------+--------+-------------+-------+-------------+---------+--------+--------------------------+----------------------+------------------+--------------------+--------------------+-------------+---------+\n",
      "only showing top 3 rows\n",
      "\n",
      "+--------------------------------------------+\n",
      "|CallType                                    |\n",
      "+--------------------------------------------+\n",
      "|Elevator / Escalator Rescue                 |\n",
      "|Marine Fire                                 |\n",
      "|Aircraft Emergency                          |\n",
      "|Confined Space / Structure Collapse         |\n",
      "|Administrative                              |\n",
      "|Alarms                                      |\n",
      "|Odor (Strange / Unknown)                    |\n",
      "|Citizen Assist / Service Call               |\n",
      "|HazMat                                      |\n",
      "|Watercraft in Distress                      |\n",
      "|Explosion                                   |\n",
      "|Oil Spill                                   |\n",
      "|Vehicle Fire                                |\n",
      "|Suspicious Package                          |\n",
      "|Extrication / Entrapped (Machinery, Vehicle)|\n",
      "|Other                                       |\n",
      "|Outside Fire                                |\n",
      "|Traffic Collision                           |\n",
      "|Assist Police                               |\n",
      "|Gas Leak (Natural and LP Gases)             |\n",
      "+--------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>CallType</th><th>CallTypeCount</th></tr>\n",
       "<tr><td>Medical Incident</td><td>113794</td></tr>\n",
       "<tr><td>Structure Fire</td><td>23319</td></tr>\n",
       "<tr><td>Alarms</td><td>19406</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+----------------+-------------+\n",
       "|        CallType|CallTypeCount|\n",
       "+----------------+-------------+\n",
       "|Medical Incident|       113794|\n",
       "|  Structure Fire|        23319|\n",
       "|          Alarms|        19406|\n",
       "+----------------+-------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 여기에 실습 코드를 작성하고 실행하세요 (Shift+Enter)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=red>5. [고급]</font> 샌프란시스코 긴급출동 데이터 CSV 파일인 \"data/learning-spark/sf-fire-calls.csv\"를 읽고 다음과 같은 질문도 실습해 보면 재미있을 것 같습니다\n",
    "#### 1. 2018 년의 모든 화재 신고 유형은 무엇 이었습니까?\n",
    "#### 2. 2018 년의 몇 월에 화재 신고가 가장 많았습니까?\n",
    "#### 3. 샌프란시스코에서 2018 년에 가장 많은 화재 신고가 발생한 지역은 어디입니까?\n",
    "#### 4. 2018 년에 화재 신고에 대한 응답 시간이 가장 나쁜 지역은 어디입니까?\n",
    "#### 5. 2018 년 중 어느 주에 화재 신고가 가장 많았습니까?\n",
    "#### 6. 이웃, 우편 번호, 화재 전화 건수간에 상관 관계가 있습니까?\n",
    "#### 7. Parquet 파일 또는 SQL 테이블을 사용하여이 데이터를 저장하고 다시 읽을 수있는 방법은 무엇입니까?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 참고자료\n",
    "\n",
    "#### 1. [Spark Programming Guide](https://spark.apache.org/docs/latest/sql-programming-guide.html)\n",
    "#### 2. [PySpark SQL Modules Documentation](https://spark.apache.org/docs/latest/api/python/pyspark.sql.html)\n",
    "#### 3. <a href=\"https://spark.apache.org/docs/3.0.1/api/sql/\" target=\"_blank\">PySpark 3.0.1 Builtin Functions</a>\n",
    "#### 4. [PySpark Search](https://spark.apache.org/docs/latest/api/python/search.html)\n",
    "#### 5. [Pyspark Functions](https://spark.apache.org/docs/latest/api/python/pyspark.sql.html?#module-pyspark.sql.functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
